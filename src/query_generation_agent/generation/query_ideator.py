"""
Query Ideator

Generates initial SQL query candidates from insights and dataset metadata.
"""

import logging
from typing import Any, Dict, List, Optional, Tuple

from ..clients.gemini_client import GeminiClient
from ..models.request_models import DatasetMetadata

logger = logging.getLogger(__name__)


class QueryIdeator:
    """
    Generates initial SQL query candidates using LLM.
    
    Takes an insight and dataset schemas, generates multiple query candidates
    that could answer the insight from different angles.
    """
    
    def __init__(self, gemini_client: GeminiClient):
        """
        Initialize query ideator.
        
        Args:
            gemini_client: Gemini client for generation
        """
        self.gemini_client = gemini_client
    
    def generate_candidates(
        self,
        insight: str,
        datasets: List[DatasetMetadata],
        num_queries: int = 3
    ) -> Tuple[bool, Optional[str], List[Dict[str, str]], Dict[str, int]]:
        """
        Generate initial query candidates.
        
        Args:
            insight: Data science insight/question to answer
            datasets: List of available datasets with schemas
            num_queries: Number of query candidates to generate
            
        Returns:
            Tuple of (success, error_message, list of query candidates, usage_metadata)
            Each query candidate is a dict with 'sql' and 'description' keys
        """
        empty_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
        
        logger.info(f"Generating {num_queries} query candidates for insight: {insight[:100]}...")
        
        # Convert datasets to dict format for Gemini client
        dataset_dicts = self._prepare_datasets(datasets)
        
        # Generate queries using Gemini
        success, error_msg, queries, usage = self.gemini_client.generate_queries(
            insight=insight,
            datasets=dataset_dicts,
            num_queries=num_queries
        )
        
        if not success:
            logger.error(f"Failed to generate queries: {error_msg}")
            return False, error_msg, [], usage
        
        if not queries:
            error_msg = "No queries generated by LLM"
            logger.error(error_msg)
            return False, error_msg, [], usage
        
        # Validate that we have the expected fields
        valid_queries = []
        for i, query in enumerate(queries):
            if not isinstance(query, dict):
                logger.warning(f"Query {i} is not a dictionary, skipping")
                continue
            
            sql = query.get("sql", "").strip()
            description = query.get("description", "").strip()
            
            if not sql:
                logger.warning(f"Query {i} has no SQL, skipping")
                continue
            
            if not description:
                description = f"Query candidate {i+1}"
            
            valid_queries.append({
                "sql": sql,
                "description": description
            })
        
        if not valid_queries:
            error_msg = "All generated queries were invalid"
            logger.error(error_msg)
            return False, error_msg, [], usage
        
        logger.info(f"Successfully generated {len(valid_queries)} valid query candidates")
        
        # Log each generated query for visibility
        for i, query in enumerate(valid_queries, 1):
            logger.info(f"Generated Query #{i}:")
            logger.info(f"Description: {query['description']}")
            logger.info(f"SQL:\n{query['sql']}")
            logger.info("-" * 80)
        
        return True, None, valid_queries, usage
    
    def _prepare_datasets(self, datasets: List[DatasetMetadata]) -> List[Dict[str, Any]]:
        """
        Convert DatasetMetadata objects to dictionaries for Gemini client.
        
        Args:
            datasets: List of DatasetMetadata objects
            
        Returns:
            List of dataset dictionaries with rich metadata
        """
        dataset_dicts = []
        
        for dataset in datasets:
            dataset_dict = {
                "project_id": dataset.project_id,
                "dataset_id": dataset.dataset_id,
                "table_id": dataset.table_id,
                "asset_type": dataset.asset_type,
                "description": dataset.description,
                
                # Size metrics
                "row_count": dataset.row_count,
                "size_bytes": dataset.size_bytes,
                "column_count": dataset.column_count,
                
                # Rich metadata fields
                "schema": dataset.schema,
                "schema_fields": dataset.schema_fields,  # Keep for backwards compatibility
                "column_profiles": dataset.column_profiles,
                "lineage": dataset.lineage,
                "analytical_insights": dataset.analytical_insights,
                "key_metrics": dataset.key_metrics,
                
                # Legacy/optional
                "full_markdown": dataset.full_markdown,
                "has_pii": dataset.has_pii,
                "has_phi": dataset.has_phi,
                "environment": dataset.environment,
                "tags": dataset.tags
            }
            
            dataset_dicts.append(dataset_dict)
        
        return dataset_dicts
    
    def generate_single_query(
        self,
        insight: str,
        datasets: List[DatasetMetadata]
    ) -> Tuple[bool, Optional[str], Optional[Dict[str, str]]]:
        """
        Generate a single query candidate.
        
        Args:
            insight: Data science insight/question to answer
            datasets: List of available datasets with schemas
            
        Returns:
            Tuple of (success, error_message, query candidate dict)
        """
        success, error_msg, queries = self.generate_candidates(
            insight=insight,
            datasets=datasets,
            num_queries=1
        )
        
        if not success or not queries:
            return False, error_msg, None
        
        return True, None, queries[0]
    
    def analyze_datasets(self, datasets: List[DatasetMetadata]) -> Dict[str, Any]:
        """
        Analyze datasets to provide summary information.
        
        Args:
            datasets: List of datasets to analyze
            
        Returns:
            Dictionary with dataset analysis
        """
        analysis = {
            "total_datasets": len(datasets),
            "total_tables": len([d for d in datasets if d.asset_type == "table"]),
            "total_views": len([d for d in datasets if d.asset_type == "view"]),
            "total_columns": sum(d.column_count or 0 for d in datasets),
            "total_rows": sum(d.row_count or 0 for d in datasets),
            "has_pii": any(d.has_pii for d in datasets),
            "has_phi": any(d.has_phi for d in datasets),
            "tables": []
        }
        
        for dataset in datasets:
            analysis["tables"].append({
                "full_name": dataset.get_full_table_id(),
                "row_count": dataset.row_count,
                "column_count": dataset.column_count,
                "has_pii": dataset.has_pii,
                "has_phi": dataset.has_phi
            })
        
        return analysis

